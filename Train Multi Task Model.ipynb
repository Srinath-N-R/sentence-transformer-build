{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bed516d-36b3-48d8-978e-a50ab3d77073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tokenizer import Tokenizer\n",
    "\n",
    "import regex as re\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from enums import CLS_ID, PAD_ID, IGNORE_INDEX, MAX_LEN, DROPOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf0765-dfa0-4fd1-95e9-b1f84d87c55a",
   "metadata": {},
   "source": [
    "# Sentence Transformer Multi-Task Expansion Overview\n",
    "\n",
    "## Dataset\n",
    "* MASSIVE dataset (English split) for multi-task learning, which contains User utterances paired with:\n",
    "\n",
    "> Intent labels (classification task)\n",
    "\n",
    "> Slot annotations for Named Entity Recognition (NER) (sequence tagging task)\n",
    "\n",
    "\n",
    "* Key steps:\n",
    "\n",
    "> BPE tokenization is performed using a custom tokenizer.\n",
    "\n",
    "> Slot labels are aligned with BPE pieces, expanding one label across subword units.\n",
    "\n",
    "> Both input IDs and slot labels are padded/truncated to a maximum length (MAX_LEN).\n",
    " \n",
    "\n",
    "* Oversampling is used during training to give more weight to examples containing at least one NER tag (to handle class imbalance).\n",
    "\n",
    "\n",
    "\n",
    "## Multi-Task Model Architecture\n",
    "\n",
    "* The multitask model builds on top of the SentenceTransformer backbone:\n",
    "\n",
    "* Intent Classifier\n",
    "\n",
    "> A simple Linear layer applied on the [CLS] token embedding for intent classification.\n",
    "\n",
    "* NER Tagger\n",
    "\n",
    "> A 2-layer bidirectional LSTM applied on the output sequence embeddings.\n",
    "\n",
    "> A 2-layer MLP (LayerNorm → Linear → GELU → Dropout → Linear) classifies each token position.\n",
    "\n",
    "## Design choice\n",
    "Initially, only the new heads were trained. After multiple unfreezing backbone experiments, unfreezing the full backbone gave better performance.\n",
    "\n",
    "## Loss Function\n",
    "\n",
    "* Intent Loss\n",
    "\n",
    "> Standard CrossEntropyLoss on the intent classification output.\n",
    "\n",
    "* NER Loss\n",
    "\n",
    "> CrossEntropyLoss applied token-wise, with class weighting to emphasize rare NER labels.\n",
    "\n",
    "> The loss ignores padding and CLS tokens (using IGNORE_INDEX).\n",
    "\n",
    "#### The final loss is the sum of intent loss and NER loss.\n",
    "\n",
    "## Training phase details:\n",
    "\n",
    "> Weighted Random Sampler to balance NER-positive examples.\n",
    "\n",
    "> Mixed Precision Training (AMP) for faster and memory-efficient training.\n",
    "\n",
    "> Gradient clipping for stability.\n",
    "\n",
    "> Cosine Annealing LR scheduler.\n",
    "\n",
    "> Early stopping based on validation loss.\n",
    "\n",
    "## Inference\n",
    "* During inference:\n",
    "\n",
    "> Input sentences are tokenized and passed through the multitask model.\n",
    "\n",
    "> The model predicts: Intent label (single prediction). And NER tags for each token position (sequence prediction).\n",
    "\n",
    "* A simple sanity check shows:\n",
    "\n",
    "> Intent classification performs reasonably well early on.\n",
    "\n",
    "> NER tagging performance could improve with larger models, more data, or task-specific pretraining.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0522fb48-e113-4563-bf5d-16e077161933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, tokenizer_path, split):\n",
    "        self.tokenizer = Tokenizer(tokenizer_path) # load tokenizer\n",
    "        self.pat = self.tokenizer.pat # get compiled regex pattern\n",
    "        self.IGNORE_INDEX = IGNORE_INDEX # used for values with ' ' or PAD or CLS tokens.\n",
    "        self.CLS_ID = CLS_ID\n",
    "        self.PAD_ID = PAD_ID\n",
    "        self.dataset = load_dataset(\"qanastek/MASSIVE\", \"en-US\", split=split) # Load the english NER+IntentClassification dataset based on split\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ex = self.dataset[idx]\n",
    "        \n",
    "        text  = ex[\"utt\"]\n",
    "        slots = ex[\"ner_tags\"]\n",
    "        intent = ex[\"intent\"]\n",
    "        \n",
    "        word_spans = [(m.group(), m.span()) for m in re.finditer(r\"\\S+\", text)]        \n",
    "        pieces_with_spans = [(m.group(), m.span()) for m in re.finditer(self.pat, text)]\n",
    "        \n",
    "        piece_labels = []\n",
    "        for piece, (start, end) in pieces_with_spans:\n",
    "            for idx, (_, (w0, w1)) in enumerate(word_spans):\n",
    "                if w0 <= start < w1:\n",
    "                    piece_labels.append(slots[idx])\n",
    "                    break\n",
    "            else:\n",
    "                piece_labels.append(self.IGNORE_INDEX)\n",
    "        \n",
    "        # Expand to BPE tokens\n",
    "        token_pieces = self.tokenizer.encode(text)\n",
    "        flat_ids     = [self.CLS_ID]\n",
    "        flat_labels  = [self.IGNORE_INDEX]\n",
    "        \n",
    "        for tok_ids, lab in zip(token_pieces, piece_labels):\n",
    "            flat_ids.extend(tok_ids)\n",
    "            flat_labels.extend([lab] * len(tok_ids))\n",
    "        \n",
    "\n",
    "        return [flat_ids, flat_labels, intent]\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    flat_ids, flat_labels, intents = zip(*batch)\n",
    "\n",
    "    # Compute the joint max length (capped by MAX_LEN)\n",
    "    raw_max = max(max(len(ids), len(labs)) for ids, labs in zip(flat_ids, flat_labels))\n",
    "    L = min(raw_max, MAX_LEN)\n",
    "\n",
    "    # Pad or truncate *both* ids and labels to length L\n",
    "    input_ids = []\n",
    "    slot_labels = []\n",
    "    attention_mask = []\n",
    "    for ids, labs in zip(flat_ids, flat_labels):\n",
    "        ids = ids[:L]\n",
    "        labs = labs[:L]\n",
    "\n",
    "        pad_len = L - len(ids)\n",
    "        input_ids.append(ids + [PAD_ID] * pad_len)\n",
    "        slot_labels.append(labs + [IGNORE_INDEX] * pad_len)\n",
    "        attention_mask.append([1]*len(ids) + [0]*pad_len)\n",
    "\n",
    "    # Stack to form tensors\n",
    "    input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "    attention_mask = torch.tensor(attention_mask, dtype=torch.long)\n",
    "    slot_labels = torch.tensor(slot_labels, dtype=torch.long)\n",
    "    intent_labels = torch.tensor(intents, dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"slot_labels\": slot_labels,\n",
    "        \"intent_labels\": intent_labels,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46abc3e-9d58-4e35-a856-e29849525113",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MultiTaskDataset(\"bpe_merged.json\", \"train\")\n",
    "validation_ds = MultiTaskDataset(\"bpe_merged.json\", \"validation\")\n",
    "test_ds = MultiTaskDataset(\"bpe_merged.json\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e3eebc-7f07-482c-9e16-0d2ba2f743e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling data with ner tags because they are under-represneted in the training dataset.\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "pos_indicator = []\n",
    "for flat_ids, flat_labels, intent in train_ds:\n",
    "    has_positive = any((lab != IGNORE_INDEX and lab != 0) for lab in flat_labels)\n",
    "    pos_indicator.append(1 if has_positive else 0)\n",
    "\n",
    "pos_alpha = 5.0\n",
    "neg_alpha = 3.0\n",
    "\n",
    "weights = [pos_alpha if p==1 else neg_alpha for p in pos_indicator]\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights,\n",
    "    num_samples=len(weights),\n",
    "    replacement=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335a5a06-bca4-491c-90e7-d34bce1d3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding unique number of intents and ner tags.\n",
    "num_intents = len(set(train_ds.dataset[\"intent\"] + validation_ds.dataset[\"intent\"] + test_ds.dataset[\"intent\"]))\n",
    "num_ner_tags = train_ds.dataset.features[\"ner_tags\"].feature.num_classes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff603ae-0314-405a-9ae7-6eabaab7b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=32,\n",
    "    sampler=sampler,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    validation_ds,\n",
    "    batch_size=32, shuffle=False,\n",
    "    num_workers=0, pin_memory=True,\n",
    "    collate_fn=collate\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=32, shuffle=False,\n",
    "    num_workers=0, pin_memory=True,\n",
    "    collate_fn=collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d534d1e2-fa60-46c1-80b7-7b526367d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Backbone = pre‐trained SentenceTransformer, plus:\n",
    "     - intent model: simple linear on [CLS]\n",
    "     - NER model: 2×BiLSTM → 2‐layer MLP on each timestep\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence_encoder: nn.Module,\n",
    "        d_model: int,\n",
    "        proj_dim: int,\n",
    "        num_intents: int,\n",
    "        num_ner_tags: int,\n",
    "        dropout: float = DROPOUT,\n",
    "        freeze_encoder: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = sentence_encoder\n",
    "\n",
    "        # intent head\n",
    "        self.intent_classifier = nn.Linear(proj_dim, num_intents)\n",
    "\n",
    "        # NER head\n",
    "        self.ner_lstm = nn.LSTM(\n",
    "            input_size=d_model,\n",
    "            hidden_size=d_model//2,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if 2 > 1 else 0.0\n",
    "        )\n",
    "        self.ner_mlp = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, num_ner_tags)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # encode\n",
    "        cls_emb, seq_emb = self.encoder(input_ids, attention_mask=attention_mask, return_all=True)\n",
    "        intent_logits = self.intent_classifier(cls_emb)\n",
    "        lstm_out, _ = self.ner_lstm(seq_emb)\n",
    "        ner_logits  = self.ner_mlp(lstm_out)\n",
    "        return intent_logits, ner_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccea6b98-12d4-4b35-9fe0-a42afd1f1199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sent_transformer import SentenceTransformer\n",
    "from enums import VOCAB_SIZE, D_MODEL, NHEAD, NUM_LAYERS, PROJ_DIM, DROPOUT\n",
    "\n",
    "# Load PreTrained Sentence Encoder.\n",
    "encoder = SentenceTransformer(\n",
    "            vocab_size=VOCAB_SIZE, d_model=D_MODEL, nhead=NHEAD, num_layers=NUM_LAYERS, proj_dim=PROJ_DIM, dropout=DROPOUT\n",
    "        )\n",
    "\n",
    "encoder.load_state_dict(torch.load('best_encoder.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bbf974-8321-4557-b2e9-5bf8e6980dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train: 100%|██████████████████████████| 360/360 [00:29<00:00, 12.00it/s]\n",
      "Epoch 1 Val:   0%|                                       | 0/64 [00:00<?, ?it/s]/Users/srinathramalingam/miniconda3/envs/sent-transform/lib/python3.10/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Epoch 1 Val: 100%|██████████████████████████████| 64/64 [00:02<00:00, 29.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 — train_loss=6.47528  val_loss=5.66544  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train: 100%|██████████████████████████| 360/360 [00:31<00:00, 11.59it/s]\n",
      "Epoch 2 Val: 100%|██████████████████████████████| 64/64 [00:02<00:00, 29.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500 — train_loss=5.44485  val_loss=5.11691  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train: 100%|██████████████████████████| 360/360 [00:30<00:00, 11.65it/s]\n",
      "Epoch 3 Val: 100%|██████████████████████████████| 64/64 [00:02<00:00, 27.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/500 — train_loss=4.99013  val_loss=4.79890  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train: 100%|██████████████████████████| 360/360 [00:38<00:00,  9.30it/s]\n",
      "Epoch 4 Val: 100%|██████████████████████████████| 64/64 [00:03<00:00, 20.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/500 — train_loss=4.65059  val_loss=4.61544  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train: 100%|██████████████████████████| 360/360 [00:38<00:00,  9.28it/s]\n",
      "Epoch 5 Val: 100%|██████████████████████████████| 64/64 [00:02<00:00, 25.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/500 — train_loss=4.48988  val_loss=4.46833  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train: 100%|██████████████████████████| 360/360 [00:37<00:00,  9.70it/s]\n",
      "Epoch 6 Val: 100%|██████████████████████████████| 64/64 [00:02<00:00, 22.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/500 — train_loss=4.32144  val_loss=4.38340  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train: 100%|██████████████████████████| 360/360 [00:39<00:00,  9.01it/s]\n",
      "Epoch 7 Val: 100%|██████████████████████████████| 64/64 [00:02<00:00, 25.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/500 — train_loss=4.15267  val_loss=4.27848  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train: 100%|██████████████████████████| 360/360 [00:38<00:00,  9.34it/s]\n",
      "Epoch 8 Val: 100%|██████████████████████████████| 64/64 [00:02<00:00, 23.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/500 — train_loss=4.04518  val_loss=4.19301  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train: 100%|██████████████████████████| 360/360 [00:37<00:00,  9.71it/s]\n",
      "Epoch 9 Val: 100%|██████████████████████████████| 64/64 [00:02<00:00, 25.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500 — train_loss=3.92093  val_loss=4.15606  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train: 100%|█████████████████████████| 360/360 [00:40<00:00,  8.93it/s]\n",
      "Epoch 10 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 23.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500 — train_loss=3.87599  val_loss=4.09593  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train: 100%|█████████████████████████| 360/360 [00:39<00:00,  9.07it/s]\n",
      "Epoch 11 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500 — train_loss=3.76851  val_loss=4.05496  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train: 100%|█████████████████████████| 360/360 [00:38<00:00,  9.38it/s]\n",
      "Epoch 12 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 22.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500 — train_loss=3.67930  val_loss=4.01540  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train: 100%|█████████████████████████| 360/360 [00:34<00:00, 10.50it/s]\n",
      "Epoch 13 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/500 — train_loss=3.63410  val_loss=3.98235  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train: 100%|█████████████████████████| 360/360 [00:31<00:00, 11.35it/s]\n",
      "Epoch 14 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 28.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/500 — train_loss=3.53167  val_loss=3.93293  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Train: 100%|█████████████████████████| 360/360 [00:32<00:00, 11.18it/s]\n",
      "Epoch 15 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 22.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/500 — train_loss=3.47029  val_loss=3.93580  lr=5.0e-05\n",
      "  ↳ No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Train: 100%|█████████████████████████| 360/360 [00:36<00:00,  9.74it/s]\n",
      "Epoch 16 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/500 — train_loss=3.44868  val_loss=3.91388  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Train: 100%|█████████████████████████| 360/360 [00:41<00:00,  8.68it/s]\n",
      "Epoch 17 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500 — train_loss=3.37780  val_loss=3.89755  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Train: 100%|█████████████████████████| 360/360 [00:35<00:00, 10.00it/s]\n",
      "Epoch 18 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/500 — train_loss=3.32050  val_loss=3.85002  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Train: 100%|█████████████████████████| 360/360 [00:38<00:00,  9.29it/s]\n",
      "Epoch 19 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/500 — train_loss=3.28095  val_loss=3.85798  lr=5.0e-05\n",
      "  ↳ No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Train: 100%|█████████████████████████| 360/360 [00:39<00:00,  9.02it/s]\n",
      "Epoch 20 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/500 — train_loss=3.22935  val_loss=3.82517  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Train: 100%|█████████████████████████| 360/360 [00:42<00:00,  8.45it/s]\n",
      "Epoch 21 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/500 — train_loss=3.20240  val_loss=3.80907  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Train: 100%|█████████████████████████| 360/360 [00:38<00:00,  9.42it/s]\n",
      "Epoch 22 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 27.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500 — train_loss=3.18498  val_loss=3.76892  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Train: 100%|█████████████████████████| 360/360 [00:31<00:00, 11.60it/s]\n",
      "Epoch 23 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500 — train_loss=3.12497  val_loss=3.78784  lr=5.0e-05\n",
      "  ↳ No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Train: 100%|█████████████████████████| 360/360 [00:31<00:00, 11.44it/s]\n",
      "Epoch 24 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 26.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500 — train_loss=3.08083  val_loss=3.76415  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Train: 100%|█████████████████████████| 360/360 [00:42<00:00,  8.54it/s]\n",
      "Epoch 25 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500 — train_loss=3.04667  val_loss=3.74696  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Train: 100%|█████████████████████████| 360/360 [00:43<00:00,  8.20it/s]\n",
      "Epoch 26 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500 — train_loss=3.00353  val_loss=3.73345  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Train: 100%|█████████████████████████| 360/360 [00:42<00:00,  8.46it/s]\n",
      "Epoch 27 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 21.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500 — train_loss=3.00477  val_loss=3.75959  lr=5.0e-05\n",
      "  ↳ No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Train: 100%|█████████████████████████| 360/360 [00:41<00:00,  8.59it/s]\n",
      "Epoch 28 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 21.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500 — train_loss=2.97399  val_loss=3.74448  lr=5.0e-05\n",
      "  ↳ No improvement for 2 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Train: 100%|█████████████████████████| 360/360 [00:42<00:00,  8.45it/s]\n",
      "Epoch 29 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 21.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500 — train_loss=2.93440  val_loss=3.72384  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Train: 100%|█████████████████████████| 360/360 [00:43<00:00,  8.25it/s]\n",
      "Epoch 30 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 19.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500 — train_loss=2.87670  val_loss=3.70255  lr=5.0e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Train: 100%|█████████████████████████| 360/360 [00:43<00:00,  8.22it/s]\n",
      "Epoch 31 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500 — train_loss=2.86865  val_loss=3.71390  lr=5.0e-05\n",
      "  ↳ No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Train: 100%|█████████████████████████| 360/360 [00:41<00:00,  8.59it/s]\n",
      "Epoch 32 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/500 — train_loss=2.87922  val_loss=3.72067  lr=4.9e-05\n",
      "  ↳ No improvement for 2 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Train: 100%|█████████████████████████| 360/360 [00:44<00:00,  8.12it/s]\n",
      "Epoch 33 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 19.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/500 — train_loss=2.85089  val_loss=3.69623  lr=4.9e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Train: 100%|█████████████████████████| 360/360 [00:42<00:00,  8.43it/s]\n",
      "Epoch 34 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 19.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/500 — train_loss=2.82408  val_loss=3.70895  lr=4.9e-05\n",
      "  ↳ No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Train: 100%|█████████████████████████| 360/360 [00:41<00:00,  8.74it/s]\n",
      "Epoch 35 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 21.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/500 — train_loss=2.75990  val_loss=3.67709  lr=4.9e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Train: 100%|█████████████████████████| 360/360 [00:38<00:00,  9.24it/s]\n",
      "Epoch 36 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/500 — train_loss=2.74447  val_loss=3.68558  lr=4.9e-05\n",
      "  ↳ No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Train: 100%|█████████████████████████| 360/360 [00:38<00:00,  9.32it/s]\n",
      "Epoch 37 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 24.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/500 — train_loss=2.71042  val_loss=3.67154  lr=4.9e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Train: 100%|█████████████████████████| 360/360 [00:38<00:00,  9.47it/s]\n",
      "Epoch 38 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 23.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/500 — train_loss=2.69420  val_loss=3.65832  lr=4.9e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Train: 100%|█████████████████████████| 360/360 [00:41<00:00,  8.72it/s]\n",
      "Epoch 39 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/500 — train_loss=2.72038  val_loss=3.66981  lr=4.9e-05\n",
      "  ↳ No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Train: 100%|█████████████████████████| 360/360 [00:39<00:00,  9.17it/s]\n",
      "Epoch 40 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 19.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500 — train_loss=2.66745  val_loss=3.67334  lr=4.9e-05\n",
      "  ↳ No improvement for 2 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Train: 100%|█████████████████████████| 360/360 [00:40<00:00,  8.99it/s]\n",
      "Epoch 41 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 27.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500 — train_loss=2.67989  val_loss=3.65137  lr=4.9e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Train: 100%|█████████████████████████| 360/360 [00:39<00:00,  9.18it/s]\n",
      "Epoch 42 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500 — train_loss=2.62011  val_loss=3.66198  lr=4.9e-05\n",
      "  ↳ No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Train: 100%|█████████████████████████| 360/360 [00:37<00:00,  9.48it/s]\n",
      "Epoch 43 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/500 — train_loss=2.61695  val_loss=3.66739  lr=4.9e-05\n",
      "  ↳ No improvement for 2 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Train: 100%|█████████████████████████| 360/360 [00:38<00:00,  9.29it/s]\n",
      "Epoch 44 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 25.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500 — train_loss=2.58712  val_loss=3.67482  lr=4.9e-05\n",
      "  ↳ No improvement for 3 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Train: 100%|█████████████████████████| 360/360 [00:38<00:00,  9.24it/s]\n",
      "Epoch 45 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 22.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500 — train_loss=2.60076  val_loss=3.62240  lr=4.9e-05\n",
      "  ↳ New best MultiTaskModel saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Train: 100%|█████████████████████████| 360/360 [00:39<00:00,  9.05it/s]\n",
      "Epoch 46 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 24.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500 — train_loss=2.57241  val_loss=3.64758  lr=4.9e-05\n",
      "  ↳ No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Train: 100%|█████████████████████████| 360/360 [00:41<00:00,  8.76it/s]\n",
      "Epoch 47 Val: 100%|█████████████████████████████| 64/64 [00:03<00:00, 20.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/500 — train_loss=2.57086  val_loss=3.64969  lr=4.9e-05\n",
      "  ↳ No improvement for 2 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Train: 100%|█████████████████████████| 360/360 [00:42<00:00,  8.52it/s]\n",
      "Epoch 48 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500 — train_loss=2.56847  val_loss=3.64161  lr=4.9e-05\n",
      "  ↳ No improvement for 3 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Train: 100%|█████████████████████████| 360/360 [00:41<00:00,  8.59it/s]\n",
      "Epoch 49 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500 — train_loss=2.53413  val_loss=3.64725  lr=4.9e-05\n",
      "  ↳ No improvement for 4 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Train: 100%|█████████████████████████| 360/360 [00:40<00:00,  8.99it/s]\n",
      "Epoch 50 Val: 100%|█████████████████████████████| 64/64 [00:02<00:00, 23.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500 — train_loss=2.49843  val_loss=3.62813  lr=4.9e-05\n",
      "  ↳ No improvement for 5 epoch(s).\n",
      "Stopping early after 5 epochs without improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize MultiTaskModel\n",
    "model = MultiTaskModel(\n",
    "    sentence_encoder=encoder,\n",
    "    d_model=D_MODEL,\n",
    "    proj_dim=PROJ_DIM,\n",
    "    num_intents=num_intents,\n",
    "    num_ner_tags=num_ner_tags,\n",
    "    freeze_encoder=True\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# I tried various combinations of layer freezing. ie: freezing the whole backbone, \n",
    "# unfreezing the last 2 layers of the backbone, unfreezing the last 2 layers of the backbone along with some encoder layers\n",
    "# and unfreezing the whole backbone.\n",
    "\n",
    "# I ended up unfreezing the whole backbone for eval accuracy.\n",
    "\n",
    "encoder_params = []\n",
    "for n,p in model.encoder.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        encoder_params.append(p)\n",
    "        \n",
    "head_params = (\n",
    "    list(model.intent_classifier.parameters()) +\n",
    "    list(model.ner_lstm.parameters()) +\n",
    "    list(model.ner_mlp.parameters())\n",
    ")\n",
    "\n",
    "\n",
    "opt = AdamW([\n",
    "    {'params': encoder_params, 'lr': 5e-5},   # fine‐tune top transformer layers with a really low LR.\n",
    "    {'params': head_params, 'lr': 1e-3},   # train new heads from scratch with high LR for faster convergence.\n",
    "], weight_decay=1e-2)\n",
    "\n",
    "\n",
    "epochs = 500\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "\n",
    "# AMP setup\n",
    "use_amp = torch.cuda.is_available()\n",
    "scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "\n",
    "# Checkpointing and early stopping setup\n",
    "checkpoint_dir = \"checkpoints_multitask\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "no_improve = 0\n",
    "\n",
    "intent_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "weights = torch.ones(num_ner_tags)\n",
    "weights *= 3\n",
    "weights[[0,-1]] = 1\n",
    "ner_loss_fn = nn.CrossEntropyLoss(weight=weights, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "\n",
    "# Training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch} Train\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        slot_labels = batch[\"slot_labels\"].to(device)\n",
    "        intent_labels = batch[\"intent_labels\"].to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        if use_amp:\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                intent_logits, ner_logits = model(input_ids, attention_mask)\n",
    "                intent_loss = intent_loss_fn(intent_logits, intent_labels)\n",
    "                ner_loss = ner_loss_fn(ner_logits.view(-1, num_ner_tags), slot_labels.view(-1))\n",
    "                loss = intent_loss + ner_loss\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            intent_logits, ner_logits = model(input_ids, attention_mask)\n",
    "            intent_loss = intent_loss_fn(intent_logits, intent_labels)\n",
    "            ner_loss = ner_loss_fn(ner_logits.view(-1, num_ner_tags), slot_labels.view(-1))\n",
    "            loss = intent_loss + ner_loss\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch} Val\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            slot_labels = batch[\"slot_labels\"].to(device)\n",
    "            intent_labels = batch[\"intent_labels\"].to(device)\n",
    "\n",
    "            if use_amp:\n",
    "                with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                    intent_logits, ner_logits = model(input_ids, attention_mask)\n",
    "                    intent_loss = intent_loss_fn(intent_logits, intent_labels)\n",
    "                    ner_loss = ner_loss_fn(ner_logits.view(-1, num_ner_tags), slot_labels.view(-1))\n",
    "                    loss = intent_loss + ner_loss\n",
    "            else:\n",
    "                intent_logits, ner_logits = model(input_ids, attention_mask)\n",
    "                intent_loss = intent_loss_fn(intent_logits, intent_labels)\n",
    "                ner_loss = ner_loss_fn(ner_logits.view(-1, num_ner_tags), slot_labels.view(-1))\n",
    "                loss = intent_loss + ner_loss\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Learning Rate Schedule\n",
    "    scheduler.step()\n",
    "    lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs} — \"\n",
    "          f\"train_loss={train_loss:.5f}  val_loss={val_loss:.5f}  lr={lr:.1e}\")\n",
    "\n",
    "    # Saving Checkpoints\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': opt.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "    }, os.path.join(checkpoint_dir, f\"multitask_epoch_{epoch}.pt\"))\n",
    "\n",
    "    # Early Stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), \"best_multitask_model.pt\")\n",
    "        print(\"  ↳ New best MultiTaskModel saved.\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        print(f\"  ↳ No improvement for {no_improve} epoch(s).\")\n",
    "        if no_improve >= patience:\n",
    "            print(f\"Stopping early after {patience} epochs without improvement.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5cc545c-0bc5-481f-ab28-ed1bd4be6b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent prediction: 46\n",
      "intent label     : 46\n",
      "ner prediction: [0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7]\n",
      "ner lablel    : [111, 0, 0, 111, 0, 111, 7, 7, 7, 111, 0, 0]\n",
      "\n",
      "intent prediction: 31\n",
      "intent label     : 31\n",
      "ner prediction: [0, 0, 0, 0, 0, 59, 59, 59, 59, 59, 59, 59, 59, 0]\n",
      "ner lablel    : [111, 0, 0, 111, 0, 0, 111, 0, 111, 0, 111, 0, 0, 0]\n",
      "\n",
      "intent prediction: 1\n",
      "intent label     : 1\n",
      "ner prediction: [0, 0, 0, 0, 0, 77, 77, 77, 77, 77, 0, 0, 0, 0]\n",
      "ner lablel    : [111, 0, 111, 0, 111, 77, 77, 77, 77, 77, 111, 20, 20, 20]\n",
      "\n",
      "intent prediction: 57\n",
      "intent label     : 57\n",
      "ner prediction: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 69, 69, 69, 69, 69, 69, 69, 69]\n",
      "ner lablel    : [111, 0, 0, 111, 0, 111, 0, 111, 0, 0, 0, 111, 0, 111, 0, 111, 69, 69, 69, 69]\n",
      "\n",
      "intent prediction: 10\n",
      "intent label     : 7\n",
      "ner prediction: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "ner lablel    : [111, 0, 0, 0, 111, 0, 0, 0]\n",
      "\n",
      "intent prediction: 53\n",
      "intent label     : 1\n",
      "ner prediction: [0, 0, 80, 0, 0, 0]\n",
      "ner lablel    : [111, 22, 22, 22, 111, 24]\n",
      "\n",
      "intent prediction: 57\n",
      "intent label     : 57\n",
      "ner prediction: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 69, 69, 69, 69, 69, 69, 69, 69]\n",
      "ner lablel    : [111, 0, 0, 111, 0, 111, 0, 111, 0, 0, 0, 111, 0, 111, 0, 111, 69, 69, 69, 69]\n",
      "\n",
      "intent prediction: 21\n",
      "intent label     : 21\n",
      "ner prediction: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "ner lablel    : [111, 0, 0, 0, 111, 0, 111, 0, 111, 0, 0, 0]\n",
      "\n",
      "intent prediction: 20\n",
      "intent label     : 20\n",
      "ner prediction: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9]\n",
      "ner lablel    : [111, 0, 0, 0, 111, 0, 0, 0, 0, 0, 111, 0, 111, 0, 111, 0, 0]\n",
      "\n",
      "intent prediction: 19\n",
      "intent label     : 19\n",
      "ner prediction: [0, 0, 0, 0, 0, 0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 44, 44, 44, 44, 44, 44]\n",
      "ner lablel    : [111, 0, 0, 111, 0, 111, 0, 0, 111, 0, 111, 33, 33, 33, 33, 33, 111, 7, 7, 7, 7]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/43/28bd6rrs7qlb2z8bs12rlsgc0000gn/T/ipykernel_34900/3279847629.py:18: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  ner_labels = list(map(int, np.array(slot_labels)[0]))\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check on a few samples on the test dataset\n",
    "# Upon a quick check, intent classification performs reasonably well.\n",
    "# And the NER model needs further training of the backbone on a larger architecture and dataset. \n",
    "# But this is a good first step as we see some okay predictions.\n",
    "\n",
    "for idx in np.random.randint(1,100,10):\n",
    "    batch = collate([test_ds[int(idx)]])\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    slot_labels = batch[\"slot_labels\"].to(device)\n",
    "    intent_labels = batch[\"intent_labels\"].to(device)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        intent_logits, ner_logits = model(input_ids, attention_mask)\n",
    "        intent_loss = intent_loss_fn(intent_logits, intent_labels)\n",
    "        ner_loss = ner_loss_fn(ner_logits.view(-1, num_ner_tags), slot_labels.view(-1))\n",
    "\n",
    "        intent_preds = int(np.argmax(intent_logits))\n",
    "        intent_labels = intent_labels[0]    \n",
    "        \n",
    "        ner_preds = list(map(int, (map(np.argmax, ner_logits[0]))))\n",
    "        ner_labels = list(map(int, np.array(slot_labels)[0]))\n",
    "\n",
    "    print(f\"intent prediction: {intent_preds}\")\n",
    "    print(f\"intent label     : {intent_labels}\")\n",
    "    print(f\"ner prediction: {ner_preds}\")\n",
    "    print(f\"ner lablel    : {ner_labels}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec7456a-a78b-48fb-9bbe-a6bd2ec0a752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
