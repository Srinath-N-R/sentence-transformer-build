{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90a01d1-04e8-4a92-8db2-860996ad493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tokenizer import Tokenizer\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from enums import PAD_ID, MAX_LEN, CLS_ID\n",
    "from sent_transformer import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad4f705-27ae-4004-991e-53e4300a918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STSB trainval triplets: 100%|█████████| 13227/13227 [00:00<00:00, 727609.73it/s]\n",
      "QQP train: 100%|█████████████████████| 101762/101762 [00:03<00:00, 29732.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triplets: 2808290\n",
      " Train: 1965802\n",
      " Val:   561658\n",
      " Test:  280830\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load and merge STSB train + validation datasets\n",
    "sts = load_dataset(\"sentence-transformers/stsb\")\n",
    "sts_trainval = concatenate_datasets([sts[\"train\"], sts[\"validation\"]])\n",
    "\n",
    "\n",
    "# Create associated sentences map\n",
    "pairs = defaultdict(list)\n",
    "for row in sts_trainval:\n",
    "    s1, s2, score = row[\"sentence1\"], row[\"sentence2\"], row[\"score\"]\n",
    "    pairs[s1].append((s2, score))\n",
    "    pairs[s2].append((s1, score))\n",
    "\n",
    "# Create a sentence pool to randomly sample negatives.\n",
    "sent_pool = list(set(sts_trainval[\"sentence1\"] + sts_trainval[\"sentence2\"]))\n",
    "\n",
    "# Set thresholds for positive, negative, and num triplets for each anchor \n",
    "POS_T, NEG_T, K = 0.6, 0.5, 3\n",
    "\n",
    "# Generate triplets for STSB dataset by randomly sampling extra negatives from sent_pool.\n",
    "all_triplets = set()\n",
    "for anchor, lst in tqdm(pairs.items(), desc=\"STSB trainval triplets\"):\n",
    "    pos = [s for s, sc in lst if sc >= POS_T]\n",
    "    neg = [s for s, sc in lst if sc <= NEG_T]\n",
    "    if not pos:\n",
    "        continue\n",
    "    for p in pos:\n",
    "        for _ in range(K):\n",
    "            if neg:\n",
    "                n = random.choice(neg)\n",
    "            else:\n",
    "                n = random.choice(sent_pool)\n",
    "                while n in (anchor, p):\n",
    "                    n = random.choice(sent_pool)\n",
    "            all_triplets.add((anchor, p, n))\n",
    "\n",
    "\n",
    "# Load QQP_triplets dataset\n",
    "qqp = load_dataset(\"embedding-data/QQP_triplets\")\n",
    "for split in qqp:\n",
    "    for row in tqdm(qqp[split], desc=f\"QQP {split}\"):\n",
    "        query = row[\"set\"][\"query\"]\n",
    "        positives = row[\"set\"][\"pos\"]\n",
    "        negatives = row[\"set\"][\"neg\"]\n",
    "        for p in positives:\n",
    "            for n in negatives:\n",
    "                all_triplets.add((query, p, n))\n",
    "\n",
    "# Shuffle\n",
    "all_triplets = list(all_triplets)\n",
    "random.seed(42)\n",
    "random.shuffle(all_triplets)\n",
    "\n",
    "# 70/20/10 Train/Val/Test split\n",
    "n = len(all_triplets)\n",
    "n_train = int(0.7 * n)\n",
    "n_val   = int(0.2 * n)\n",
    "\n",
    "train_data = all_triplets[:n_train]\n",
    "val_data   = all_triplets[n_train : n_train + n_val]\n",
    "test_data  = all_triplets[n_train + n_val : ]\n",
    "\n",
    "\n",
    "print(f\"Total triplets: {n}\")\n",
    "print(f\" Train: {len(train_data)}\")\n",
    "print(f\" Val:   {len(val_data)}\")\n",
    "print(f\" Test:  {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86167fd0-1654-4e58-8571-9b65a5e2c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, triplets, tokenizer, max_len=MAX_LEN):\n",
    "        self.triplets = triplets\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a,p,n = self.triplets[idx]\n",
    "        return [self.tok.tokenize(s).tolist() for s in (a,p,n)]\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    a, p, n = zip(*batch)\n",
    "\n",
    "    def pad(seq):\n",
    "        L = max(len(s) for s in seq)\n",
    "        batch_ids = [s + [PAD_ID] * (L - len(s)) for s in seq]\n",
    "        attn_mask = [[1] * len(s) + [0] * (L - len(s)) for s in seq]\n",
    "        return (\n",
    "            torch.tensor(batch_ids, dtype=torch.long),\n",
    "            torch.tensor(attn_mask, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    a_ids, a_mask = pad(a)\n",
    "    p_ids, p_mask = pad(p)\n",
    "    n_ids, n_mask = pad(n)\n",
    "\n",
    "    return (a_ids, a_mask), (p_ids, p_mask), (n_ids, n_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e930921b-e4df-4499-937c-9370941c9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\"bpe_merged.json\")\n",
    "train_dataset = TripletDataset(train_data, tokenizer)\n",
    "val_dataset = TripletDataset(val_data, tokenizer)\n",
    "test_dataset   = TripletDataset(test_data, tokenizer)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TripletDataset(train_data, tokenizer),\n",
    "    batch_size=32, shuffle=True,\n",
    "    num_workers=0, pin_memory=True,\n",
    "    collate_fn=collate\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    TripletDataset(val_data, tokenizer),\n",
    "    batch_size=32, shuffle=False,\n",
    "    num_workers=0, pin_memory=True,\n",
    "    collate_fn=collate\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    TripletDataset(test_data, tokenizer),\n",
    "    batch_size=32, shuffle=False,\n",
    "    num_workers=0, pin_memory=True,\n",
    "    collate_fn=collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b1f7c8-37ad-40c5-8238-9a8f0a00fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48b3b973-0a8d-4e66-b2aa-cb72988ea040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499a66e629244b9b8247b59eb673e4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/382 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13731796af645eeb5b794a41c9f236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75547f08bc5473e8931768b4dea6dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 128)\n",
       "    (token_type_embeddings): Embedding(2, 128)\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-1): 2 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1) Choose a smaller BERT\n",
    "teacher_name     = \"google/bert_uncased_L-2_H-128_A-2\"   # hidden_size=256\n",
    "teacher_tokenizer= AutoTokenizer.from_pretrained(teacher_name)\n",
    "teacher_model    = AutoModel.from_pretrained(teacher_name)\n",
    "teacher_model.eval()\n",
    "\n",
    "# # 2) In your distillation loop\n",
    "# raw_texts = [ \"This is an example.\", \"Another sentence.\" ]\n",
    "# teach_inputs = teacher_tokenizer(\n",
    "#     raw_texts, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "# )\n",
    "# with torch.no_grad():\n",
    "#     out = teacher_model(**teach_inputs).last_hidden_state  # (B, L, 256)\n",
    "#     teacher_cls = out[:,0]                                 # (B, 256)\n",
    "\n",
    "# # 3) Your student still runs on BPE + custom encoder → student_cls: (B, D)\n",
    "# #    Then distillation: e.g. MSE:\n",
    "# loss = F.mse_loss(student_cls, teacher_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efb404c7-ddc6-4945-9f03-d5563c074dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts = [\"Hi, How are you\", \"How are you, Hi\", \"Hi\", \"Wonder ful saar\"]       # e.g. list[str] you collate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bacc1259-6db9-40ef-adf2-a41dc3bbcb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.8823256492614746,\n",
       "  0.4203495383262634,\n",
       "  -0.7122400999069214,\n",
       "  -1.6795321702957153,\n",
       "  -0.1700838953256607,\n",
       "  0.018848402425646782,\n",
       "  0.11936243623495102,\n",
       "  0.6452649235725403,\n",
       "  -1.188864827156067,\n",
       "  -0.3175344169139862,\n",
       "  -0.022278079763054848,\n",
       "  0.27063825726509094,\n",
       "  -0.1428239643573761,\n",
       "  0.6041097640991211,\n",
       "  1.7108962535858154,\n",
       "  -1.1337039470672607,\n",
       "  -0.7393425107002258,\n",
       "  0.47491124272346497,\n",
       "  -1.1764651536941528,\n",
       "  1.3366515636444092,\n",
       "  -0.47980427742004395,\n",
       "  0.5489088892936707,\n",
       "  1.4174871444702148,\n",
       "  0.19421899318695068,\n",
       "  1.1056174039840698,\n",
       "  -0.3610375225543976,\n",
       "  0.5508883595466614,\n",
       "  0.5334464311599731,\n",
       "  0.4596266746520996,\n",
       "  -0.2989594638347626,\n",
       "  -1.8627790212631226,\n",
       "  -2.7980494499206543,\n",
       "  -0.5149377584457397,\n",
       "  0.5198287963867188,\n",
       "  0.5482035875320435,\n",
       "  -0.22754310071468353,\n",
       "  0.4483339488506317,\n",
       "  0.3482033908367157,\n",
       "  -1.9715547561645508,\n",
       "  -0.82817143201828,\n",
       "  1.2674686908721924,\n",
       "  -1.0244967937469482,\n",
       "  0.508489191532135,\n",
       "  -1.007757306098938,\n",
       "  -0.4269471764564514,\n",
       "  -1.0143775939941406,\n",
       "  -0.539951741695404,\n",
       "  -0.5628682971000671,\n",
       "  -0.09607674926519394,\n",
       "  -0.145512193441391,\n",
       "  0.017803490161895752,\n",
       "  1.210593819618225,\n",
       "  0.671972930431366,\n",
       "  -0.20289437472820282,\n",
       "  0.6896862387657166,\n",
       "  -1.1918213367462158,\n",
       "  1.4074636697769165,\n",
       "  -0.7873315811157227,\n",
       "  -0.9095802307128906,\n",
       "  0.6561946868896484,\n",
       "  0.6421197056770325,\n",
       "  -1.6817914247512817,\n",
       "  -1.17411208152771,\n",
       "  0.06388707458972931,\n",
       "  -1.0510560274124146,\n",
       "  -0.41317611932754517,\n",
       "  -0.3641848862171173,\n",
       "  0.794651448726654,\n",
       "  -0.041420791298151016,\n",
       "  0.5601152777671814,\n",
       "  -0.8774900436401367,\n",
       "  0.15816424787044525,\n",
       "  0.41436949372291565,\n",
       "  0.2987450063228607,\n",
       "  -0.9997753500938416,\n",
       "  -0.30246981978416443,\n",
       "  -0.6036542654037476,\n",
       "  -0.40581896901130676,\n",
       "  1.2354352474212646,\n",
       "  0.35513830184936523,\n",
       "  -0.2191443294286728,\n",
       "  0.020521845668554306,\n",
       "  0.9040080904960632,\n",
       "  0.8555176854133606,\n",
       "  -0.3518182337284088,\n",
       "  -0.8716317415237427,\n",
       "  -1.0575765371322632,\n",
       "  -0.49028322100639343,\n",
       "  1.646264910697937,\n",
       "  -1.1694447994232178,\n",
       "  1.9552764892578125,\n",
       "  -0.11837814748287201,\n",
       "  -1.3704512119293213,\n",
       "  1.5623074769973755,\n",
       "  0.2666023075580597,\n",
       "  1.0045381784439087,\n",
       "  0.35251951217651367,\n",
       "  -0.5403534770011902,\n",
       "  0.4978269934654236,\n",
       "  0.5044933557510376,\n",
       "  -0.0065236263908445835,\n",
       "  0.4683261215686798,\n",
       "  0.38025331497192383,\n",
       "  -0.8722307085990906,\n",
       "  1.8435903787612915,\n",
       "  -1.2682981491088867,\n",
       "  -0.08461008220911026,\n",
       "  -0.27723759412765503,\n",
       "  -0.30598869919776917,\n",
       "  -0.4423513114452362,\n",
       "  -0.2610418200492859,\n",
       "  1.0627646446228027,\n",
       "  1.7485586404800415,\n",
       "  -1.0498121976852417,\n",
       "  0.12389784306287766,\n",
       "  0.5183581709861755,\n",
       "  -0.07434540241956711,\n",
       "  -1.0604801177978516,\n",
       "  1.189970850944519,\n",
       "  0.23937925696372986,\n",
       "  0.04501977190375328,\n",
       "  2.279522657394409,\n",
       "  1.0028154850006104,\n",
       "  -2.4397332668304443,\n",
       "  -2.528724431991577,\n",
       "  -1.0591527223587036,\n",
       "  -0.5495436787605286,\n",
       "  0.9493938088417053],\n",
       " [-0.9457756280899048,\n",
       "  0.5375615358352661,\n",
       "  -0.6823357939720154,\n",
       "  -1.5766502618789673,\n",
       "  -0.27369385957717896,\n",
       "  0.09489936381578445,\n",
       "  0.15635737776756287,\n",
       "  0.6788157224655151,\n",
       "  -1.0721673965454102,\n",
       "  -0.2783847749233246,\n",
       "  -0.011873900890350342,\n",
       "  0.3910173773765564,\n",
       "  -0.1210104376077652,\n",
       "  0.6014750599861145,\n",
       "  1.8307607173919678,\n",
       "  -1.1866095066070557,\n",
       "  -0.8055042624473572,\n",
       "  0.4612375795841217,\n",
       "  -1.1063563823699951,\n",
       "  1.2917054891586304,\n",
       "  -0.4654606878757477,\n",
       "  0.4630274474620819,\n",
       "  1.439391016960144,\n",
       "  0.22836075723171234,\n",
       "  0.9495726823806763,\n",
       "  -0.2762041687965393,\n",
       "  0.5543274283409119,\n",
       "  0.461732417345047,\n",
       "  0.41814279556274414,\n",
       "  -0.3437526524066925,\n",
       "  -1.94033682346344,\n",
       "  -2.8455159664154053,\n",
       "  -0.5616834759712219,\n",
       "  0.5858267545700073,\n",
       "  0.6360762715339661,\n",
       "  -0.09157326072454453,\n",
       "  0.4065532684326172,\n",
       "  0.2376871109008789,\n",
       "  -1.8904173374176025,\n",
       "  -0.9418551325798035,\n",
       "  1.2037334442138672,\n",
       "  -1.0479626655578613,\n",
       "  0.3673904836177826,\n",
       "  -1.0172443389892578,\n",
       "  -0.4778585731983185,\n",
       "  -0.9347108602523804,\n",
       "  -0.6001121401786804,\n",
       "  -0.5862255096435547,\n",
       "  0.034281011670827866,\n",
       "  -0.27119460701942444,\n",
       "  -0.011037503369152546,\n",
       "  1.1839540004730225,\n",
       "  0.49663981795310974,\n",
       "  -0.17513790726661682,\n",
       "  0.7054191827774048,\n",
       "  -1.142372965812683,\n",
       "  1.5409491062164307,\n",
       "  -0.6727232336997986,\n",
       "  -0.9937740564346313,\n",
       "  0.649272084236145,\n",
       "  0.6558399200439453,\n",
       "  -1.6867445707321167,\n",
       "  -0.9486204385757446,\n",
       "  0.0025809407234191895,\n",
       "  -1.080379843711853,\n",
       "  -0.5296734571456909,\n",
       "  -0.43250131607055664,\n",
       "  0.8860424160957336,\n",
       "  -0.1604989618062973,\n",
       "  0.5748387575149536,\n",
       "  -0.8256470561027527,\n",
       "  0.10619264096021652,\n",
       "  0.3719227612018585,\n",
       "  -0.03072241321206093,\n",
       "  -1.0415765047073364,\n",
       "  -0.23303191363811493,\n",
       "  -0.7099990248680115,\n",
       "  -0.4226819574832916,\n",
       "  1.3916027545928955,\n",
       "  0.369890958070755,\n",
       "  -0.23215143382549286,\n",
       "  -0.05793125182390213,\n",
       "  0.7952195405960083,\n",
       "  0.7400015592575073,\n",
       "  -0.2870120108127594,\n",
       "  -0.9339860081672668,\n",
       "  -0.9336604475975037,\n",
       "  -0.443393737077713,\n",
       "  1.5063632726669312,\n",
       "  -1.1034431457519531,\n",
       "  2.056389331817627,\n",
       "  -0.11463019996881485,\n",
       "  -1.3095426559448242,\n",
       "  1.6383014917373657,\n",
       "  0.257490873336792,\n",
       "  1.0986689329147339,\n",
       "  0.3945414423942566,\n",
       "  -0.5631793737411499,\n",
       "  0.6298980712890625,\n",
       "  0.5102171301841736,\n",
       "  -0.11877637356519699,\n",
       "  0.5931626558303833,\n",
       "  0.4502693712711334,\n",
       "  -0.8760935068130493,\n",
       "  1.7683743238449097,\n",
       "  -1.2837255001068115,\n",
       "  -0.022567059844732285,\n",
       "  -0.29271677136421204,\n",
       "  -0.29537153244018555,\n",
       "  -0.4997313320636749,\n",
       "  -0.33867621421813965,\n",
       "  1.1889406442642212,\n",
       "  1.6514261960983276,\n",
       "  -1.0247970819473267,\n",
       "  0.06652265042066574,\n",
       "  0.6072262525558472,\n",
       "  -0.10282405465841293,\n",
       "  -0.9747629761695862,\n",
       "  1.1988108158111572,\n",
       "  0.3115972578525543,\n",
       "  -0.10975145548582077,\n",
       "  2.30082106590271,\n",
       "  0.9207821488380432,\n",
       "  -2.344085216522217,\n",
       "  -2.527986764907837,\n",
       "  -1.0374265909194946,\n",
       "  -0.5417022705078125,\n",
       "  1.01884925365448],\n",
       " [-1.4053219556808472,\n",
       "  0.8513927459716797,\n",
       "  -1.6712846755981445,\n",
       "  -2.3438022136688232,\n",
       "  -0.5960659384727478,\n",
       "  0.16614806652069092,\n",
       "  0.11757864058017731,\n",
       "  0.15330377221107483,\n",
       "  -0.8415235280990601,\n",
       "  0.39513102173805237,\n",
       "  0.2608143389225006,\n",
       "  -0.24791796505451202,\n",
       "  -2.0335590839385986,\n",
       "  0.6616343259811401,\n",
       "  1.1716703176498413,\n",
       "  -1.835248351097107,\n",
       "  -0.6173984408378601,\n",
       "  0.45602908730506897,\n",
       "  -1.7447965145111084,\n",
       "  1.012149691581726,\n",
       "  0.35327082872390747,\n",
       "  -0.3926336467266083,\n",
       "  1.6637932062149048,\n",
       "  0.98420649766922,\n",
       "  0.410806268453598,\n",
       "  0.35869958996772766,\n",
       "  0.6731877326965332,\n",
       "  0.8823180794715881,\n",
       "  0.7020050883293152,\n",
       "  -0.33793148398399353,\n",
       "  -1.6273757219314575,\n",
       "  -1.2844288349151611,\n",
       "  -0.6290640234947205,\n",
       "  1.0194286108016968,\n",
       "  0.739904522895813,\n",
       "  -0.5480924844741821,\n",
       "  0.5668202638626099,\n",
       "  -0.20956173539161682,\n",
       "  -2.576148271560669,\n",
       "  -1.716815710067749,\n",
       "  0.9492431879043579,\n",
       "  -0.6446800827980042,\n",
       "  1.4502233266830444,\n",
       "  -0.746940553188324,\n",
       "  -0.4997828006744385,\n",
       "  -0.7939690947532654,\n",
       "  -0.7723929286003113,\n",
       "  -1.0409553050994873,\n",
       "  0.9846252799034119,\n",
       "  -0.5866832137107849,\n",
       "  -0.6877699494361877,\n",
       "  2.2713558673858643,\n",
       "  0.31696364283561707,\n",
       "  0.021827515214681625,\n",
       "  0.5119885206222534,\n",
       "  -1.4486186504364014,\n",
       "  0.740996778011322,\n",
       "  1.051694631576538,\n",
       "  -1.71625554561615,\n",
       "  1.9510542154312134,\n",
       "  0.703529417514801,\n",
       "  -1.0696243047714233,\n",
       "  -0.7947903275489807,\n",
       "  0.07660792768001556,\n",
       "  -1.0834215879440308,\n",
       "  -0.24931858479976654,\n",
       "  -0.14229628443717957,\n",
       "  0.2134154587984085,\n",
       "  0.4310738146305084,\n",
       "  0.6724125146865845,\n",
       "  0.12706544995307922,\n",
       "  -0.022231148555874825,\n",
       "  0.0005955227534286678,\n",
       "  -0.9821451306343079,\n",
       "  -0.7403804659843445,\n",
       "  -0.07839417457580566,\n",
       "  -0.01197187602519989,\n",
       "  0.30678272247314453,\n",
       "  1.9361861944198608,\n",
       "  1.7504949569702148,\n",
       "  0.41723746061325073,\n",
       "  -0.42102503776550293,\n",
       "  0.45161738991737366,\n",
       "  -0.5267763137817383,\n",
       "  -0.5955610275268555,\n",
       "  -0.28439193964004517,\n",
       "  -0.6029830574989319,\n",
       "  0.035692065954208374,\n",
       "  2.776214122772217,\n",
       "  -1.7296936511993408,\n",
       "  1.8816778659820557,\n",
       "  0.4317259192466736,\n",
       "  -1.8012030124664307,\n",
       "  1.4404691457748413,\n",
       "  0.11110491305589676,\n",
       "  1.2416566610336304,\n",
       "  0.8087133765220642,\n",
       "  -0.4073967933654785,\n",
       "  -0.10166884958744049,\n",
       "  0.15466073155403137,\n",
       "  -1.3987970352172852,\n",
       "  0.009462186135351658,\n",
       "  0.2889266908168793,\n",
       "  -1.0938645601272583,\n",
       "  1.1007487773895264,\n",
       "  -1.647902488708496,\n",
       "  -0.5617514848709106,\n",
       "  0.7365452647209167,\n",
       "  0.5706878304481506,\n",
       "  -1.5952774286270142,\n",
       "  0.051174912601709366,\n",
       "  0.9955105185508728,\n",
       "  0.7748904228210449,\n",
       "  -0.4550301134586334,\n",
       "  0.512641966342926,\n",
       "  1.238698124885559,\n",
       "  -0.5368817448616028,\n",
       "  -0.20214049518108368,\n",
       "  1.0191380977630615,\n",
       "  0.21981872618198395,\n",
       "  -0.3566757142543793,\n",
       "  1.4914531707763672,\n",
       "  0.5786186456680298,\n",
       "  -1.5941047668457031,\n",
       "  -1.687667965888977,\n",
       "  -1.5095951557159424,\n",
       "  -0.9433975219726562,\n",
       "  0.1680224984884262],\n",
       " [-1.4166258573532104,\n",
       "  -0.5314891934394836,\n",
       "  -0.8674100637435913,\n",
       "  -0.7621715664863586,\n",
       "  -0.8812700510025024,\n",
       "  -0.041415054351091385,\n",
       "  -0.6349191665649414,\n",
       "  0.3771994411945343,\n",
       "  -1.0605456829071045,\n",
       "  -0.8410550355911255,\n",
       "  1.463734745979309,\n",
       "  -0.6128568649291992,\n",
       "  -0.996606171131134,\n",
       "  -0.17797748744487762,\n",
       "  2.1898810863494873,\n",
       "  -0.5291028618812561,\n",
       "  -1.7809616327285767,\n",
       "  0.8570683598518372,\n",
       "  -1.4839736223220825,\n",
       "  0.17682933807373047,\n",
       "  -0.15537479519844055,\n",
       "  -0.1993604600429535,\n",
       "  0.7456403374671936,\n",
       "  0.47765836119651794,\n",
       "  1.0290340185165405,\n",
       "  -0.3461534082889557,\n",
       "  0.3756903111934662,\n",
       "  -0.27370861172676086,\n",
       "  0.4854269027709961,\n",
       "  0.026996074244379997,\n",
       "  -0.31281620264053345,\n",
       "  -0.5466892123222351,\n",
       "  -0.6627272963523865,\n",
       "  1.0956385135650635,\n",
       "  0.07696152478456497,\n",
       "  -1.3133348226547241,\n",
       "  -0.23793916404247284,\n",
       "  0.5084243416786194,\n",
       "  -2.487039566040039,\n",
       "  -1.3761508464813232,\n",
       "  0.6210954785346985,\n",
       "  -0.83940190076828,\n",
       "  -0.49669918417930603,\n",
       "  -0.24042093753814697,\n",
       "  0.2872588634490967,\n",
       "  -0.682237446308136,\n",
       "  -0.46275538206100464,\n",
       "  -1.2224619388580322,\n",
       "  0.3451671302318573,\n",
       "  0.4051990509033203,\n",
       "  -0.2807980179786682,\n",
       "  1.7073469161987305,\n",
       "  0.5968670845031738,\n",
       "  -0.3344469964504242,\n",
       "  -0.6706221699714661,\n",
       "  -1.206563949584961,\n",
       "  0.8155880570411682,\n",
       "  0.15472187101840973,\n",
       "  -0.5726988911628723,\n",
       "  2.127894163131714,\n",
       "  0.4749647080898285,\n",
       "  -0.21196399629116058,\n",
       "  -0.5959072113037109,\n",
       "  -0.8060107231140137,\n",
       "  -1.3686031103134155,\n",
       "  -0.27358195185661316,\n",
       "  -0.08282148838043213,\n",
       "  0.14590846002101898,\n",
       "  -0.8674302101135254,\n",
       "  -0.269991010427475,\n",
       "  -0.2696937620639801,\n",
       "  0.54737788438797,\n",
       "  0.35008808970451355,\n",
       "  -0.8125483393669128,\n",
       "  -0.23316749930381775,\n",
       "  -0.2558591067790985,\n",
       "  0.014845813624560833,\n",
       "  0.482368528842926,\n",
       "  2.1670823097229004,\n",
       "  0.2869362235069275,\n",
       "  0.38615602254867554,\n",
       "  0.049615126103162766,\n",
       "  0.5158053040504456,\n",
       "  -0.009405664168298244,\n",
       "  -0.4897877275943756,\n",
       "  0.1722799390554428,\n",
       "  -0.4303967356681824,\n",
       "  0.14197532832622528,\n",
       "  1.5889960527420044,\n",
       "  -1.9633299112319946,\n",
       "  1.3007961511611938,\n",
       "  0.10750255733728409,\n",
       "  -0.9551467299461365,\n",
       "  1.4722203016281128,\n",
       "  -0.05861000344157219,\n",
       "  1.6800485849380493,\n",
       "  0.6392096877098083,\n",
       "  -0.5955479741096497,\n",
       "  0.6066188812255859,\n",
       "  0.8165503144264221,\n",
       "  -0.8364505767822266,\n",
       "  -0.5289440155029297,\n",
       "  0.15607915818691254,\n",
       "  0.6233711242675781,\n",
       "  0.5426588654518127,\n",
       "  -1.8492672443389893,\n",
       "  -0.805560290813446,\n",
       "  1.7010574340820312,\n",
       "  0.45675209164619446,\n",
       "  -0.5555241703987122,\n",
       "  0.11602688580751419,\n",
       "  0.6502456068992615,\n",
       "  1.4883325099945068,\n",
       "  0.9744824171066284,\n",
       "  0.5092415809631348,\n",
       "  1.0234447717666626,\n",
       "  -0.7622857689857483,\n",
       "  -1.1443862915039062,\n",
       "  0.3291642367839813,\n",
       "  -0.04257720708847046,\n",
       "  0.5655956268310547,\n",
       "  0.7625736594200134,\n",
       "  1.021315336227417,\n",
       "  -0.9861860275268555,\n",
       "  -1.4559389352798462,\n",
       "  -1.3635979890823364,\n",
       "  -1.1835148334503174,\n",
       "  1.4308713674545288]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_out.last_hidden_state.mean(dim=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af39085-eec3-419f-8990-a505e627dc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
